"""
BHARATSCAM GUARDIAN â€” ANTI-FALSE-POSITIVE CORE EDITION
Revolutionary "Legitimacy-by-Default" Architecture with Verifiable Claim Deconstruction
"""

# ============================================================
# Core Philosophy: 
# False positives occur because systems hunt for scams. 
# We hunt for VERIFIABILITY & LEGITIMACY first, then derive risk.
# A message is only risky if it LACKS trust anchors, not just contains scary words.
# ============================================================

import streamlit as st
import torch
import torch.nn.functional as F
import numpy as np
import json, re, time, hashlib, sqlite3, subprocess, sys
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Tuple, Set
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from huggingface_hub import hf_hub_download

# ============================================================
# BEHAVIORAL PSYCHOLOGY & VERIFIABILITY CONFIGURATION
# ============================================================
COLORS = {
    "SAFE": "#2D936C",
    "CAUTION": "#F4A261",
    "SUSPICIOUS": "#E76F51",
    "SCAM": "#C1121C"
}

# Official corpus for semantic alignment (hashed for privacy)
LEGITIMATE_PATTERNS = {
    "bank_official": r'\b(?:HDFC|ICICI|SBI|AXIS|KOTAK|BOB|PNB)[\s]*(?:Bank|Ltd|Limited)\b|\bRBI\b|\bNPCI\b|\bIRDAI\b',
    "govt_official": r'\b(?:UIDAI|ITA|GST|EPFO|CBDT|MCA|CEIR)\b|\b(?:gov\.in|nic\.in|ac\.in)\b',
    "verifiable_ref": r'\b(?:UTR|Ref|Reference|Txn|Transaction)[\s]*[No|ID|Number]*[\s]*[:#]?\s*[A-Z0-9]{8,20}\b',
    "official_contact": r'\b(?:1800|1860)[\s]*-?[\s]*\d{3}[\s]*-?[\s]*\d{4}\b|\b(?:91|0)?\s*?[\s]*?[\s]*?[\s]*([\s]*\d{8})\b',
    "secure_url": r'\bhttps?://(?:www\.)?(?:hdfcbank\.com|icicibank\.com|sbi\.co\.in|axisbank\.com|paytm\.com|amazon\.in|flipkart\.com)[/\w.-]*\b'
}

# Scam patterns remain but are now SECONDARY
SCAM_PATTERNS = {
    "urgency_vague": r'\b(immediately|now|urgent|within\s+\d+\s+hours?)\b(?!\s+(?:to\s+)?(?:avoid|prevent)\s+.*?\b(?:fraud|unauthorized)\b)',
    "authority_impersonation": r'\b(?:(?:fake|fraud|spoof|impersonat).*?(?:RBI|Bank|Govt|Government|Police|CIBIL|IT\s+Dept))|(?:(?:RBI|Bank|Govt|Government|Police|CIBIL|IT\s+Dept).*?(?:fake|fraud|spoof|impersonat))\b',
    "unverifiable_sender": r'\b(?:Dear Customer|Valued User|Respected Sir/Madam)\b',
    "payment_redirection": r'\b(?:pay|transfer|send).*?(?:UPI|Wallet|Account).*?(?:different|alternate|new|other)\b'
}

# ============================================================
# ENHANCED GLOBALS
# ============================================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
REPO_ID = "prakhar146/scam"
LOCAL_DIR = Path("./hf_cpaft_core")
LOCAL_DIR.mkdir(exist_ok=True)
DB_PATH = Path("./trust_anchors.db")

CP_AFT_LABELS = [
    "account_threat","time_pressure","payment_request","credential_phish",
    "kyc_fraud","lottery_fraud","job_scam","delivery_scam","refund_scam",
    "investment_scam","romance_scam","charity_scam","qr_code_attack","fear_induction"
]

# ============================================================
# VERIFIABILITY & LEGITIMACY ENGINES (CORE INNOVATION)
# ============================================================

@dataclass
class Claim:
    text: str
    claim_type: str  # 'financial', 'temporal', 'identity', 'action'
    verifiability_score: float  # 0.0=unverifiable, 1.0=fully verifiable

class TrustAnchorEngine:
    """Detects trust anchors that legitimate messages MUST have"""
    def score(self, text: str) -> Tuple[float, List[str]]:
        legitimacy_hits = []
        score = 0.0
        
        for pattern_name, pattern in LEGITIMATE_PATTERNS.items():
            matches = len(re.findall(pattern, text, re.I))
            if matches > 0:
                legitimacy_hits.append(f"âœ“ {pattern_name.replace('_',' ').title()}: {matches} found")
                # Official patterns give HIGH legitimacy (0.3 each)
                if pattern_name in ["bank_official", "govt_official"]:
                    score += min(matches * 0.3, 0.4)
                # Verifiable references are strong anchors (0.25 each)
                elif pattern_name == "verifiable_ref":
                    score += min(matches * 0.25, 0.35)
                # Official contact adds legitimacy (0.2 each)
                elif pattern_name == "official_contact":
                    score += min(matches * 0.2, 0.25)
                # Secure URL is strong (0.3 each)
                elif pattern_name == "secure_url":
                    score += min(matches * 0.3, 0.4)
        
        return min(score, 1.0), legitimacy_hits

class VerifiableClaimsEngine:
    """Deconstructs message into claims and scores their verifiability"""
    def extract_claims(self, text: str) -> List[Claim]:
        """Simple regex-based claim extraction (no spaCy required)"""
        claims = []
        
        # Financial claims (amounts, numbers)
        financial_matches = re.findall(r'\b(?:â‚¹|Rs\.?|INR)\s*[\d,]+(?:\.\d{2})?\b|\b\d{6,}\b', text, re.I)
        for match in financial_matches:
            claims.append(Claim(match, "financial", 0.0))
        
        # Temporal claims
        temporal_matches = re.findall(r'\b(?:today|tomorrow|yesterday|within\s+\d+\s+(?:hour|day|week|month)s?|by\s+\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\b', text, re.I)
        for match in temporal_matches:
            claims.append(Claim(match, "temporal", 0.0))
        
        # Identity claims (organizations)
        identity_matches = re.findall(r'\b(?:RBI|NPCI|UIDAI|IT\s+Department|HDFC|ICICI|SBI|AXIS|KOTAK|Government|Police|CIBIL)\b', text, re.I)
        for match in identity_matches:
            claims.append(Claim(match, "identity", 0.0))
        
        # Action claims (verbs + objects)
        action_matches = re.findall(r'\b(?:click|pay|transfer|send|share|update|verify)\s+(?:link|amount|money|details|OTP|UPI|account)\b', text, re.I)
        for match in action_matches:
            claims.append(Claim(match, "action", 0.0))
        
        return claims
    
    def score_verifiability(self, text: str, claims: List[Claim]) -> Tuple[float, List[str]]:
        """Score how many claims can be verified without responding to message"""
        if not claims:
            return 0.0, ["No claims found"]
        
        verifiable_count = 0
        details = []
        
        for claim in claims:
            # Can this claim be verified through official channels?
            if claim.claim_type == "financial" and re.search(r'\b\d{6,}\b', claim.text):
                # Transaction IDs, UTR numbers are verifiable
                claim.verifiability_score = 0.8
                verifiable_count += 1
                details.append(f"ğŸ’° Financial claim '{claim.text}' is verifiable")
            elif claim.claim_type == "temporal" and re.search(r'\b\d{1,2}\s*(?:hour|day|week)', claim.text, re.I):
                # Time constraints - verifiable if official
                claim.verifiability_score = 0.3  # Lower score, time can be manipulated
                details.append(f"â° Temporal claim '{claim.text}' has low verifiability")
            elif claim.claim_type == "identity":
                # Identity claims need official verification
                if re.search(r'\b(?:RBI|NPCI|UIDAI|IT\s+Department)\b', claim.text, re.I):
                    claim.verifiability_score = 0.7
                    verifiable_count += 1
                    details.append(f"ğŸ›ï¸ Official identity '{claim.text}' is verifiable")
                else:
                    claim.verifiability_score = 0.1
                    details.append(f"âš ï¸ Generic identity '{claim.text}' is unverifiable")
            elif claim.claim_type == "action":
                # Actions that can be done through official app are more verifiable
                if any(word in claim.text.lower() for word in ['app', 'portal', 'website', 'official']):
                    claim.verifiability_score = 0.6
                    verifiable_count += 1
                    details.append(f"âœ… Action '{claim.text}' has official channel")
                else:
                    claim.verifiability_score = 0.0
                    details.append(f"âŒ Action '{claim.text}' requires direct response")
        
        overall_score = verifiable_count / len(claims) if claims else 0.0
        return overall_score, details

class SemanticCoherenceEngine:
    """Detects contradictions and confusion tactics used in scams"""
    def score(self, text: str) -> Tuple[float, List[str]]:
        """Returns INCOHERENCE score (0.0=clear, 1.0=confusing)"""
        issues = []
        score = 0.0
        
        # Check for multiple conflicting timeframes
        time_refs = re.findall(r'\b(immediately|now|within\s+\d+|by\s+tomorrow|asap)\b', text, re.I)
        if len(set(time_refs)) > 2:
            issues.append(f"ğŸ•’ Multiple conflicting urgencies: {set(time_refs)}")
            score += 0.3
        
        # Check for authority contradictions
        authorities = re.findall(r'\b(RBI|Government|Police|Bank|IT\s+Dept|Court)\b', text, re.I)
        if len(authorities) >= 3:
            issues.append(f"ğŸ›ï¸ Too many authorities: {authorities}")
            score += 0.25
        
        # Check for grammatical chaos (scams often have weird structure)
        sentences = re.split(r'[.!?]+', text)
        long_sentences = [s for s in sentences if len(s.split()) > 25]
        if long_sentences:
            issues.append(f"ğŸ“œ Unusually long/confusing sentences: {len(long_sentences)}")
            score += 0.15
        
        # Check for emotional vs factual imbalance
        emotion_words = len(re.findall(r'\b(urgent|immediately|freeze|arrest|cancel|terminate)\b', text, re.I))
        factual_words = len(re.findall(r'\b(reference|transaction|account|number|date|time)\b', text, re.I))
        if emotion_words > factual_words * 2:
            issues.append(f"ğŸ˜± Emotional manipulation: {emotion_words} fear words vs {factual_words} facts")
            score += 0.3
        
        return min(score, 1.0), issues

# ============================================================
# MODEL LOADER (Cached)
# ============================================================
@st.cache_resource
def load_model():
    files = [
        "config.json","model.safetensors","tokenizer.json","tokenizer_config.json",
        "special_tokens_map.json","vocab.json","merges.txt","scam_v1.json"
    ]
    for f in files:
        hf_hub_download(REPO_ID, f, repo_type="dataset", local_dir=LOCAL_DIR, local_dir_use_symlinks=False)
    tok = AutoTokenizer.from_pretrained(LOCAL_DIR)
    mdl = AutoModelForSequenceClassification.from_pretrained(LOCAL_DIR).to(DEVICE).eval()
    with open(LOCAL_DIR / "scam_v1.json") as f:
        cal = json.load(f)
    return tok, mdl, float(cal["temperature"]), np.array(cal["thresholds"])

# ============================================================
# RISK ORCHESTRATOR (CORE INNOVATION: MULTIPLICATIVE LOGIC)
# ============================================================
@dataclass
class RiskProfile:
    score: float
    level: str
    confidence: float
    triggers: Dict[str, float]
    recos: List[str]
    legitimacy_proof: List[str]
    verifiability_details: List[str]
    coherence_issues: List[str]


class CoreOrchestrator:
    def __init__(self, T, thres):
        self.T = T
        self.thres = thres
        self.trust_engine = TrustAnchorEngine()
        self.claims_engine = VerifiableClaimsEngine()
        self.coherence_engine = SemanticCoherenceEngine()

    def infer(self, text: str) -> RiskProfile:
        # Load model
        tok, mdl, _, _ = load_model()
        inputs = tok(text, return_tensors="pt", truncation=True, padding=True).to(DEVICE)

        with torch.no_grad():
            logits = mdl(**inputs).logits / self.T
            probs = torch.sigmoid(logits).cpu().numpy()[0]

        # STEP 1: Detect scam patterns (traditional approach)
        detected = probs > self.thres
        scam_signals = probs[detected].mean() if detected.any() else probs.max() * 0.25

        # STEP 2: Detect LEGITIMACY anchors (INVERSE of false positives)
        legitimacy_score, legitimacy_proof = self.trust_engine.score(text)

        # STEP 3: Score verifiability of claims
        claims = self.claims_engine.extract_claims(text)
        verifiability_score, verif_details = self.claims_engine.score_verifiability(text, claims)

        # STEP 4: Detect semantic incoherence (scam confusion tactics)
        incoherence_score, coherence_issues = self.coherence_engine.score(text)

        # CORE INNOVATION: Multiplicative risk formula
        risk_multiplier = (1 - legitimacy_score) ** 2 * (1 - verifiability_score) * (1 + incoherence_score * 0.5)
        final_risk = min(scam_signals * risk_multiplier, 1.0)

        # Dynamic thresholding based on context complexity
        if legitimacy_score > 0.5 and verifiability_score > 0.4:
            risk_thresholds = np.array([0.2, 0.4, 0.7])  # SAFE, CAUTION, SUSPICIOUS, SCAM
        else:
            risk_thresholds = np.array([0.15, 0.3, 0.5])

        level_idx = int(np.clip(final_risk / 0.35, 0, 3))
        level = ["SAFE", "CAUTION", "SUSPICIOUS", "SCAM"][level_idx]

        # Only show scam triggers if risk is substantial
        triggers = {}
        if final_risk > 0.3:
            triggers = {
                label: float(prob)
                for label, prob, is_detected in zip(CP_AFT_LABELS, probs, detected)
                if is_detected
            }

        # Recommendations based on VERIFIABILITY, not just risk
        if legitimacy_score > 0.6:
            recos = ["âœ… Message contains official trust anchors", "ğŸ“ Verify using OFFICIAL app/website only", "ğŸ” Check reference numbers in official portal"]
        elif final_risk > 0.5:
            recos = ["ğŸš¨ DO NOT respond directly", "ğŸ“ Call official number from your card/bank statement", "ğŸ”’ Enable transaction limits", "ğŸ—‘ï¸ Delete after reporting"]
        else:
            recos = ["â³ Pause before acting", "ğŸ¤” Ask: 'Can I verify this without replying?'"]

        return RiskProfile(
            round(final_risk * 100, 2),
            level,
            round((1 - np.std(probs)) * 100, 2),
            triggers,
            recos,
            legitimacy_proof,
            verif_details,
            coherence_issues
        )
# ============================================================
# STREAMLIT UI (Enhanced with Proof Display)
# ============================================================
def init_state():
    for k in ["msg","profile","stage"]:
        if k not in st.session_state:
            st.session_state[k] = None

def header():
    st.markdown("""
    <style>
    .head{background:linear-gradient(135deg,#003049 0%,#005f73 100%);color:white;padding:2rem;border-radius:12px;margin-bottom:2rem;}
    .badge{display:inline-block;background:rgba(255,255,255,.1);padding:.4rem .8rem;border-radius:20px;font-size:.8rem;margin:.2rem;}
    .proof-box{background:#f0f4f8;padding:1rem;border-radius:8px;margin:.5rem 0;border-left:4px solid #2D936C;}
    .issue-box{background:#fff5f5;padding:1rem;border-radius:8px;margin:.5rem 0;border-left:4px solid #C1121C;}
    </style>
    <div class="head">
        <h1 style="margin:0;font-size:2.5rem;">ğŸ›¡ï¸ BharatScam Guardian</h1>
        <p style="margin:.5rem 0 0 0;opacity:.9;"> Protect India: First Verify Legitimacy, Then Assess Risk</p>
        <div style="margin-top:1rem;">
            <span class="badge">ğŸ‡®ğŸ‡³ CERT-In Partner</span>
            <span class="badge">ğŸ” Legitimacy-First</span>
            <span class="badge">ğŸ§  Explainable AI</span>
        </div>
    </div>""", unsafe_allow_html=True)

def input_area():
    st.markdown("### ğŸ“¨ Paste any message (bank, delivery, job, etc.)")
    st.caption("Our AI first looks for proof of legitimacy, then scam signals.")
    msg = st.text_area("", height=200, placeholder="Paste message here...", label_visibility="collapsed")
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        if st.button("ğŸ” Analyze with Legitimacy Check", type="primary", use_container_width=True, key="analyze"):
            if msg.strip():
                st.session_state.msg = msg
                st.session_state.stage = "RUNNING"
                st.rerun()
            else:
                st.error("Please paste a message first.")
    return msg

def hero(p: RiskProfile):
    color = COLORS[p.level]
    st.markdown(f"""
    <div style='background:{color};color:white;padding:2.5rem;border-radius:16px;text-align:center;'>
        <div style='font-size:4rem;font-weight:800'>{p.score}%</div>
        <div style='font-size:1.5rem;font-weight:600;margin:.5rem 0;'>{p.level}</div>
        <div style='opacity:.9'>Confidence: {p.confidence}%</div>
    </div>""", unsafe_allow_html=True)
    
    # Show WHY the score is what it is
    st.markdown("#### ğŸ“Š Risk Breakdown")
    st.progress(float(p.score)/100.0)
    
    if p.legitimacy_proof:
        st.markdown("##### âœ… Legitimacy Anchors Detected (Risk Reducer)")
        for proof in p.legitimacy_proof[:3]:
            st.markdown(f"<div class='proof-box'>{proof}</div>", unsafe_allow_html=True)
    
    if p.coherence_issues:
        st.markdown("##### âš ï¸ Confusion Tactics Detected (Risk Amplifier)")
        for issue in p.coherence_issues[:2]:
            st.markdown(f"<div class='issue-box'>{issue}</div>", unsafe_allow_html=True)

def triggers(p: RiskProfile):
    if not p.triggers: 
        st.info("ğŸ” No strong scam patterns detected. Risk may come from lack of legitimacy proof.")
        return
    
    st.markdown("### ğŸ¯ Scam Tactics Detected")
    for trig, prob in sorted(p.triggers.items(), key=lambda x: x[1], reverse=True)[:5]:
        emoji = "ğŸ”´" if prob > 0.7 else "ğŸŸ¡"
        st.markdown(f"{emoji} **{trig.replace('_',' ').title()}** â€” {prob:.1%} match")

def actions(p: RiskProfile):
    st.markdown("### ğŸ¯ Recommended Next Steps")
    for r in p.recos:
        if "OFFICIAL" in r:
            st.success(r)
        elif "Verify" in r:
            st.info(r)
        elif "DO NOT" in r:
            st.error(r)
        elif "Pause" in r:
            st.warning(r)

def verifiability_section(p: RiskProfile):
    if p.verifiability_details:
        with st.expander("ğŸ”¬ Detailed Claim Analysis"):
            for detail in p.verifiability_details:
                st.markdown(f"- {detail}")

# ============================================================
# MAIN PAGE FLOW
# ============================================================
def main():
    st.set_page_config(page_title="BharatScam Guardian", page_icon="ğŸ›¡ï¸", layout="centered")
    init_state()
    header()
    input_area()
    
    if st.session_state.stage == "RUNNING":
        progress=st.progress(0)
        status=st.empty()
        steps=["ğŸ” Checking legitimacy anchorsâ€¦","ğŸ“„ Verifying claimsâ€¦","ğŸ§  Analyzing coherenceâ€¦","âš ï¸ Computing riskâ€¦"]
        for i, step in enumerate(steps):
            status.markdown(step)
            for p in range(25):
                progress.progress((i * 25 + p + 1) / 100)
                time.sleep(0.01)


                
               
        
        orch = CoreOrchestrator(*load_model()[2:])
        profile = orch.infer(st.session_state.msg)
        st.session_state.profile = profile
        st.session_state.stage = "DONE"
        st.rerun()
    
    if st.session_state.stage == "DONE" and st.session_state.profile:
        hero(st.session_state.profile)
        triggers(st.session_state.profile)
        actions(st.session_state.profile)
        verifiability_section(st.session_state.profile)
        
        if st.button("ğŸ”„ Analyze New Message", key="reset"):
            st.session_state.msg = None
            st.session_state.profile = None
            st.session_state.stage = None
            st.rerun()

if __name__ == "__main__":
    main()  for what cases it says suspcious 
